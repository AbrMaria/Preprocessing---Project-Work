{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "from io import StringIO # для чтения данных из строки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузить файл data_breast.csv. В данном файле собрана расчетная информация с обработанных изображений биоптата молочных желез женщин. Задача заключается в предсказании переменной “Diagnosis” - является ли содержимое биоптата доброкачественным (значение “B” – benign) либо злокачественным (значение “M” – malicious). Описание данных доступно на сайте https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_breast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Рассчитать основные статистики для переменных (среднее, медиана, мода, мин/макс, сред. отклонение)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчитываем основные статистики для средних значений измерений\n",
    "def describe(df, stats):\n",
    "    d = df.describe()\n",
    "    return d.append(df.agg(stats))\n",
    "\n",
    "describe(data[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']], ['median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Выбрать стратегию для работы с пропущенными значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем наличие пропущенных значений\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#пропущенных значений нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# целевая переменная (столбец diagnosis) является категориальной\n",
    "# переведем значения столбца в числа, оставив один столбец\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit( data['diagnosis'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# записываем в переменную y преобразованный столбец diagnosis\n",
    "y = pd.Series( data = le.transform( data['diagnosis'] ) )\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('diagnosis', axis=1) \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#или меняем значение в датасете\n",
    "\n",
    "def count_diagnosis(row):\n",
    "    if 'M' in row['diagnosis']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['diagnosis'] = data.apply(count_diagnosis, axis=1)\n",
    "data['diagnosis'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Unnamed: 32\"].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#избавляемся от безымянной колонки, заполненной значениями NaN\n",
    "data.drop([\"Unnamed: 32\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Рассчитать и визуализировать корреляционную матрицу для переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "sns.heatmap(corr, annot=True,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'concave points_mean': 'concave_points_mean'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'concave points_se': 'concave_points_se'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'concave points_worst': 'concave_points_worst'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#оценим корреляцию признаков с target-переменной 'diagnosis'\n",
    "data.corr()[['diagnosis']].sort_values(by='diagnosis', ascending=False).style.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выберем для наглядности ограниченный набор параметров для анализа \n",
    "data_mean = data[['diagnosis', 'concave_points_worst', 'perimeter_worst', 'concave_points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'area_mean', 'concavity_mean', 'concavity_worst', 'compactness_mean', 'compactness_worst', 'radius_se', 'perimeter_se', 'area_se']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_mean.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "sns.heatmap(data.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Визуализировать взаимосвязи между переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, vars=['diagnosis', 'concave_points_worst', 'perimeter_worst', 'concave_points_mean', 'radius_worst'],\n",
    "                 kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, vars=['diagnosis','perimeter_mean', 'area_worst', 'radius_mean', 'area_mean'],\n",
    "                 kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. С помощью статистических методов проверить взаимосвязи между переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(data['concave_points_worst'], data['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(data['perimeter_worst'], data['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим взаимосвязь target-переменной c предоставленными признаками в наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ols_string(target, array):\n",
    "    values = \" + \".join(np.delete(array, np.argwhere(array==target)))\n",
    "    return \"{0} ~ {1}\".format(target, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = smf.ols(get_ols_string('diagnosis', data.columns.values), data=data).fit()\n",
    "est_res = est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция дл чтения данных из строки\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изучим результат обучения линейной модели и \n",
    "# уберем все переменные первого порядка, для которых верна нулевая гипотеза\n",
    "table = est_res.tables[1]\n",
    "pd_table = pd.read_csv(StringIO(table.as_csv()))\n",
    "pd_table.columns = ['column', 'coef', 'std_err', 't', 'p>t', '0.025', '0.975']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем переменные первого порядка, для которых не верна нулевая гипотеза:\n",
    "columns = pd_table.sort_values(by='p>t')[(pd_table['p>t']<0.4)].column.unique()\n",
    "columns = [i.strip(' ') for i in columns]\n",
    "columns.remove('Intercept')\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим результаты линейной регрессии на \n",
    "est = smf.ols(get_ols_string('diagnosis', columns), data=data).fit()\n",
    "est_res = est.summary()\n",
    "est_res.tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#est = smf.ols(get_ols_string('diagnosis', data.columns.values), data=data).fit()\n",
    "\n",
    "est = smf.ols('diagnosis ~ concave_points_worst + perimeter_worst + concave_points_mean + radius_worst', data).fit()\n",
    "est_res = est.summary()\n",
    "est_res.tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#все выбранные показатели, кроме perimeter_worst, имеют маленький  p-value. \n",
    "#Т.е. между perimeter_worst и diagnosis нет линейной зависимости и, следовательно, от этого атрибута можно избавиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_x_lm = smf.ols('diagnosis ~ area_worst + radius_worst + concave_points_worst', data_mean).fit()\n",
    "rss = np.sum(three_x_lm.resid ** 2)\n",
    "print(\"RSS:\", rss)\n",
    "print(\"RSE:\", np.sqrt(rss / (data.shape[0] - 3 - 1)))\n",
    "print(\"R^2:\", three_x_lm.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_x_lm = smf.ols('diagnosis ~ area_worst + radius_worst', data).fit()\n",
    "rss = np.sum(two_x_lm.resid ** 2)\n",
    "print(\"RSS:\", rss)\n",
    "print(\"RSE:\", np.sqrt(rss / (data.shape[0] - 2 - 1)))\n",
    "print(\"R^2:\", two_x_lm.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Выбрать стратегию Feature Selection – сокращение размерности либо генерация новых переменных. Какой из этих двух подходов даст лучший результат при классификации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Процедура выбора наиболее значимых атрибутов называется feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы учитывались не только линейные зависимости при построении модели, расширим количество параметров и проведем для них статистический тест\n",
    "\n",
    "Для расширения параметров попробуем включить в обучающую выборку нелинейные зависимости, например перемножим все коэффициенты со всеми и изучим результаты статистических тестов, чтобы избавиться от незначительных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_cartesian = [' * '.join([i,j]) for i in columns for j in columns]\n",
    "\n",
    "# Проверим результаты линейной регрессии\n",
    "est = smf.ols(get_ols_string('diagnosis', columns+columns_cartesian), data=data).fit()\n",
    "est_res = est.summary()\n",
    "\n",
    "table = est_res.tables[1]\n",
    "pd_table = pd.read_csv(StringIO(table.as_csv()))\n",
    "pd_table.columns = ['column', 'coef', 'std_err', 't', 'p>t', '0.025', '0.975']\n",
    "pd_table_filtered = pd_table.sort_values(by='p>t')[(pd_table['p>t']<0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cобираем итоговую выборку\n",
    "# Для начала соберем все параметры первого порядка\n",
    "columns = [i.strip(' ') for i in pd_table_filtered.column.unique()]\n",
    "columns.remove('Intercept')\n",
    "parameters = data[[i for i in columns if ':' not in i]]\n",
    "\n",
    "# Теперь будем перемножать параметры второго порядка\n",
    "for i in [i for i in columns if ':' in i]:\n",
    "    i_values = i.split(\":\")\n",
    "    parameters[i] = data.apply(lambda x: x[i_values[0]]*x[i_values[1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для решения задачи\n",
    "X = parameters\n",
    "y = data['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Провести стратегию Oversampling/Undersampling, проверить дает ли она улучшение результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#посмотрим на распределение значений для target-переменной 'diagnosis'\n",
    "plt.title('Распределение положительных и отрицательных результатов тестов')\n",
    "plt.hist(y)\n",
    "\n",
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#количество доброкачественных результатов тестов и злокачественных различается, что может повлиять на переобучение модели. \n",
    "#при этом данных в исходной выборке не очень много, поэтому попробуем применить стратегию Oversampling\n",
    "#импортируем библиотеку для применения стратегии OVERSAMPLING\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled_o, y_resampled_o = SMOTE().fit_resample(X, y)\n",
    "X_train_o, X_test_o, y_train_o, y_test_o = train_test_split(X_resampled_o, y_resampled_o,  test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Распределение положительных и отрицательных результатов тестов')\n",
    "plt.hist(y_resampled_o)\n",
    "\n",
    "plt.hist(y_train_o)#после применения стратегии OVERSAMPLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Сделать кросс-валидацию данных с использованием подхода K-fold (n_folds=10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg = LogisticRegression(penalty='l1', C=0.1, solver='liblinear')\n",
    "model_logreg_o = LogisticRegression(penalty='l1', C=0.1, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели на кросс-валидации и оверсэмплинге\n",
    "cross_val_score(model_logreg_o, X_train_o, y_train_o, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели на кросс-валидации без оверсэмплинга\n",
    "cross_val_score(model_logreg, X_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg_o.fit(X_train_o, y_train_o)\n",
    "model_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели на данных с оверсемплингом\n",
    "model_logreg_o.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели на данных без оверсемплинга\n",
    "model_logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_prediction = model_logreg_o.predict(X_test)\n",
    "logreg_prediction_proba = model_logreg_o.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#овэрсэмплинг для данной задачи дает значительный прирост к точности модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Рассчитать Feature Selection для выбранных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выбрать те переменные которые по вашему мнению оптимальны для получения лучших результатов при тренировке модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сделано на шаге 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Решить задачу бинарной классификации и предсказать переменную ”Diagnosis ” протестировав как минимум 2\n",
    "алгоритма. Использовать те алгоритмы, которые позволяют предсказать вероятность класса (proba). Рассчитать и\n",
    "вывести вероятность каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit( X, y )\n",
    "predictions = model.predict_proba( X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Проверить качество классификации с использованием следующих метрик: Accuracy, F1-Score, Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "$$ Accuracy=P/N $$\n",
    "где, P – количество документов по которым классификатор принял правильное решение, а N – размер обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_test_pred)\n",
    "#или\n",
    "#accuracy_score(y_test, logreg_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "Понятно что чем выше точность и полнота, тем лучше. Но в реальной жизни максимальная точность и полнота не достижимы одновременно и приходится искать некий баланс. Поэтому, хотелось бы иметь некую метрику которая объединяла бы в себе информацию о точности и полноте нашего алгоритма.\n",
    "\n",
    "F-мера представляет собой гармоническое среднее между точностью и полнотой. Она стремится к нулю, если точность или полнота стремится к нулю.\n",
    "\n",
    "$$ F=2\\dfrac{Precision×Recall}{Precision+Recall} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, logreg_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall\n",
    "\n",
    "TP — истино-положительное решение;\n",
    "TN — истино-отрицательное решение;\n",
    "FP — ложно-положительное решение;\n",
    "FN — ложно-отрицательное решение. Тогда, точность и полнота определяются следующим образом:\n",
    "$$ Precision=TP/(TP+FP) $$$$ Recall=TP/(TP+FN) $$\n",
    "Precision - количество истинно положительных результатов от количества модельно-положительных результатов (фактически точность модели) Recall - количество истинно положительных относительно реально-положительных результатов (фактически отклик на реальность)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Precision = {0}; Recall = {1}\".\\\n",
    "    format(precision_score(y_test, logreg_prediction), recall_score(y_test, logreg_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим кривую Precision-Recall для Логистической регрессии\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, \n",
    "                                    [i[1] for i in logreg_prediction_proba])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Precision-Recall Curve for Logistic Regression')\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "sns.lineplot(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix (Матрица неточностей)\n",
    "Столбцы этой матрицы резервируются за экспертными решениями, а строки за решениями классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix для линейной регрессии\n",
    "confusion_matrix(y_test, logreg_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Проверить качество вероятности класса с использованием метрики: Brier Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common formulation of the Brier score is\n",
    "\n",
    "$$ BS={\\frac {1}{N}}\\sum \\limits _{t=1}^{N}(f_{t}-o_{t})^{2} $$\n",
    "in which  $f_{t}$ is the probability that was forecast,  $o_{t}$ the actual outcome of the event at instance t (0 if it does not happen and 1 if it does happen) and N is the number of forecasting instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brier_score_loss(y_test, [i[1] for i in logreg_prediction_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
